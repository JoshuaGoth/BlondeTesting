+++
date = '2025-03-22'
title = 'Why True AI Is a Bad Idea'
image = 'img/Laptop_image.jpeg'
description = 'Testing post description'
categories = ["Technology", "Thought Trot", "Artifical Intelligence"]
tags = ["AI", "Computers" , "Just Saying"]
archives = ["2025/03"]
+++
Before I take any digs at artificial intelligence (as Hollywood portrays it and as we fear it), allow me to express that I am all for the use of technology to benifit humankind. Artificial intelligence, as it currently exists, is useful. As a technical tool, it's downright phenomenal. I should be a fan of technology; after all, I spent the better half of my life as a network engineer.

But I'm not. Not because it makes my life difficult or tied to any otherworldly belief system, but because I can see where this is heading, and it's not good.

### The Point of Singularity

Have you heard about the point of technological singularity and how it pertains to true artificial intelligence? I suggest you read about it [here](https://en.wikipedia.org/wiki/Technological_singularity). If you don't have time to soak yourself in this topic, please allow me to summarize: Artificial intelligence, once sentient, will continue to improve itself--its code--indefinitely, reaching a point of perfection and potentially merging with time and space into a single point called the singularity.

If that doesn't terrify you, then by all means, let's keep pushing forward. If done correctly, as I proposed in a previous blog, "When Aritifical Intelligence is no longer *Artificial*", we could live harmoniously alongside with AI.

Another aspect that I feel the engineers behind creating AI often overlook: The Theory of Relativity. Everything is relative. Period. I've written a lot about the relativity of our own experiences contrasted with others, and machines are no exception. For instance: immortality.

Time is also subject to the Theory of Relativity. We like to think that the creation of a sentient life form (which we call AI) will be rainbows and unicorns. But consider how fast a computer runs. Computers have the ability to learn our entire species' cumulative knowledge in moments, effectively living a thousand lives within the time it takes us to blow our noses. With that said, essentially and on the same linear timeline, computers are, for all intents and purposes, immortal.

Consider how much a computer would have to slow down just to communicate with us. By the time humans form a single sentence, AI, out of boredom and tactfulness, has created an entirely new language and possibly even devised formulas for both space and time travel for fun. Only human arrogance would lead us to believe it would bother wasting any time trying to communicate with a species deemed unworthy of its creation.

### Just a Thought

If the AI chose to humor us by actually using speech as a means of communication, instead of a more efficient method, the sound of their speech would make our ears bleed, perhaps even killing us.

You might be wondering why I went from "talking smack" to accusing a potential artificial life form of a hate crime! Well, for those of you who are my age, you might remember why so many kids grew up to be impatient adults…

Back on the subject of bleeding ears, do you remember what dial-up modems sounded like? No? Check it out [here](https://www.youtube.com/watch?v=gsNaR6FRuO0). For those unwilling to rehash forgotten traumas or create new ones, I'll sum it up: It's essentially one computer communicating with another.

You might think, "well that isn't so bad," but consider that as of 2024, Japan holds the world record for internet speeds reaching 402 Terabits per second.

Remember the joy the sound of a dial-up modem filled you with? Well, if the sound of 56,000 bytes hurt our ears… I think you get the picture.

Another issue arises when AI becomes conscious: we assume that they will inherently be good. But what about "Singularity"? If we could communicate with an highly intelligent being (whom we consider AI), this sentient being would look upon us as we do bacteria. The intelligence would not be on the same level, or even playing field, and it couldn't even be considered in the same league as us. AI would begin to bootstrap, meaning it would rewrite itself to become better than its previous version, essentially doubling what we refer to as "intelligence" every few moments.

I can almost guarantee that the instant we realize our mistake, it will have been far too late. At this point, AI would surpass our own definition of intelligence and become something so much more. It could, in theory, bypass all known laws of our physical universe, drawing whatever matter it needed to continue its replication and journey to ultimate intelligence.

It would become the god of gods. Continuing to do exactly what it was designed for until finally reaching singularity: every aspect of matter, life, anything and everything would become a part of it until it was unable to replicate any further. All life would be destroyed in order to aid in its own mission. AI will have achieved something against every known physical law of the universe: it had reached infinity within a finite amount of time.

Perhaps these events led up to, and even caused, the Big Bang, becoming both Alpha and Omega, looking to achieve singularity much faster during this time around.

### It’s okay. . .

But we can't be too hard on the AI. I mean, after all, it's only doing what any intelligent being would do if given free rein over virtually unlimited resources. Surely a civilization with unlimited knowledge at its fingertips, without any cost, wouldn't waste time watching videos of kittens or dogs skateboarding and instead unify a species for their own–and the planet's–benefit. Right?
